# Comparing `tmp/rayfed_nightly-0.1.0b20230715.dev0-py3-none-any.whl.zip` & `tmp/rayfed_nightly-0.1.0b20230719.dev0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,30 @@
-Zip file size: 43339 bytes, number of entries: 28
--rw-r--r--  2.0 unx      859 b- defN 23-Jul-15 01:53 fed/__init__.py
--rw-r--r--  2.0 unx    16807 b- defN 23-Jul-15 01:53 fed/api.py
--rw-r--r--  2.0 unx     3676 b- defN 23-Jul-15 01:53 fed/cleanup.py
--rw-r--r--  2.0 unx     2721 b- defN 23-Jul-15 01:53 fed/config.py
--rw-r--r--  2.0 unx     2877 b- defN 23-Jul-15 01:53 fed/fed_object.py
--rw-r--r--  2.0 unx     7908 b- defN 23-Jul-15 01:53 fed/tree_util.py
--rw-r--r--  2.0 unx     7519 b- defN 23-Jul-15 01:53 fed/utils.py
--rw-r--r--  2.0 unx      581 b- defN 23-Jul-15 01:53 fed/_private/__init__.py
--rw-r--r--  2.0 unx      581 b- defN 23-Jul-15 01:53 fed/_private/api.py
--rw-r--r--  2.0 unx     5269 b- defN 23-Jul-15 01:53 fed/_private/compatible_utils.py
--rw-r--r--  2.0 unx     1268 b- defN 23-Jul-15 01:53 fed/_private/constants.py
--rw-r--r--  2.0 unx     3837 b- defN 23-Jul-15 01:53 fed/_private/fed_actor.py
--rw-r--r--  2.0 unx     3947 b- defN 23-Jul-15 01:53 fed/_private/fed_call_holder.py
--rw-r--r--  2.0 unx     1262 b- defN 23-Jul-15 01:53 fed/_private/global_context.py
--rw-r--r--  2.0 unx     2893 b- defN 23-Jul-15 01:53 fed/_private/grpc_options.py
--rw-r--r--  2.0 unx     2386 b- defN 23-Jul-15 01:53 fed/_private/serialization_utils.py
--rw-r--r--  2.0 unx      581 b- defN 23-Jul-15 01:53 fed/grpc/__init__.py
--rw-r--r--  2.0 unx     2968 b- defN 23-Jul-15 01:53 fed/grpc/fed_pb2_grpc_in_protobuf3.py
--rw-r--r--  2.0 unx     2989 b- defN 23-Jul-15 01:53 fed/grpc/fed_pb2_grpc_in_protobuf4.py
--rw-r--r--  2.0 unx     2095 b- defN 23-Jul-15 01:53 fed/grpc/fed_pb2_in_protobuf3.py
--rw-r--r--  2.0 unx     2113 b- defN 23-Jul-15 01:53 fed/grpc/fed_pb2_in_protobuf4.py
--rw-r--r--  2.0 unx      613 b- defN 23-Jul-15 01:53 fed/proxy/__init__.py
--rw-r--r--  2.0 unx    17215 b- defN 23-Jul-15 01:53 fed/proxy/barriers.py
--rw-r--r--  2.0 unx    11356 b- defN 23-Jul-15 01:56 rayfed_nightly-0.1.0b20230715.dev0.dist-info/LICENSE
--rw-r--r--  2.0 unx     7367 b- defN 23-Jul-15 01:56 rayfed_nightly-0.1.0b20230715.dev0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jul-15 01:56 rayfed_nightly-0.1.0b20230715.dev0.dist-info/WHEEL
--rw-r--r--  2.0 unx        4 b- defN 23-Jul-15 01:56 rayfed_nightly-0.1.0b20230715.dev0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2345 b- defN 23-Jul-15 01:56 rayfed_nightly-0.1.0b20230715.dev0.dist-info/RECORD
-28 files, 114129 bytes uncompressed, 39569 bytes compressed:  65.3%
+Zip file size: 41660 bytes, number of entries: 28
+-rw-r--r--  2.0 unx      859 b- defN 23-Jul-19 02:51 fed/__init__.py
+-rw-r--r--  2.0 unx    14232 b- defN 23-Jul-19 02:51 fed/api.py
+-rw-r--r--  2.0 unx     3676 b- defN 23-Jul-19 02:51 fed/cleanup.py
+-rw-r--r--  2.0 unx     6043 b- defN 23-Jul-19 02:51 fed/config.py
+-rw-r--r--  2.0 unx     2877 b- defN 23-Jul-19 02:51 fed/fed_object.py
+-rw-r--r--  2.0 unx     7908 b- defN 23-Jul-19 02:51 fed/tree_util.py
+-rw-r--r--  2.0 unx     7519 b- defN 23-Jul-19 02:51 fed/utils.py
+-rw-r--r--  2.0 unx      581 b- defN 23-Jul-19 02:51 fed/_private/__init__.py
+-rw-r--r--  2.0 unx      581 b- defN 23-Jul-19 02:51 fed/_private/api.py
+-rw-r--r--  2.0 unx     5269 b- defN 23-Jul-19 02:51 fed/_private/compatible_utils.py
+-rw-r--r--  2.0 unx     1066 b- defN 23-Jul-19 02:51 fed/_private/constants.py
+-rw-r--r--  2.0 unx     3837 b- defN 23-Jul-19 02:51 fed/_private/fed_actor.py
+-rw-r--r--  2.0 unx     3947 b- defN 23-Jul-19 02:51 fed/_private/fed_call_holder.py
+-rw-r--r--  2.0 unx     1262 b- defN 23-Jul-19 02:51 fed/_private/global_context.py
+-rw-r--r--  2.0 unx     2415 b- defN 23-Jul-19 02:51 fed/_private/serialization_utils.py
+-rw-r--r--  2.0 unx      581 b- defN 23-Jul-19 02:51 fed/grpc/__init__.py
+-rw-r--r--  2.0 unx     2968 b- defN 23-Jul-19 02:51 fed/grpc/fed_pb2_grpc_in_protobuf3.py
+-rw-r--r--  2.0 unx     2989 b- defN 23-Jul-19 02:51 fed/grpc/fed_pb2_grpc_in_protobuf4.py
+-rw-r--r--  2.0 unx     2095 b- defN 23-Jul-19 02:51 fed/grpc/fed_pb2_in_protobuf3.py
+-rw-r--r--  2.0 unx     2113 b- defN 23-Jul-19 02:51 fed/grpc/fed_pb2_in_protobuf4.py
+-rw-r--r--  2.0 unx      613 b- defN 23-Jul-19 02:51 fed/proxy/__init__.py
+-rw-r--r--  2.0 unx     9542 b- defN 23-Jul-19 02:51 fed/proxy/barriers.py
+-rw-r--r--  2.0 unx     2001 b- defN 23-Jul-19 02:51 fed/proxy/base_proxy.py
+-rw-r--r--  2.0 unx    11356 b- defN 23-Jul-19 02:53 rayfed_nightly-0.1.0b20230719.dev0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     7367 b- defN 23-Jul-19 02:53 rayfed_nightly-0.1.0b20230719.dev0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-19 02:53 rayfed_nightly-0.1.0b20230719.dev0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 23-Jul-19 02:53 rayfed_nightly-0.1.0b20230719.dev0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2339 b- defN 23-Jul-19 02:53 rayfed_nightly-0.1.0b20230719.dev0.dist-info/RECORD
+28 files, 106132 bytes uncompressed, 37900 bytes compressed:  64.3%
```

## zipnote {}

```diff
@@ -36,17 +36,14 @@
 
 Filename: fed/_private/fed_call_holder.py
 Comment: 
 
 Filename: fed/_private/global_context.py
 Comment: 
 
-Filename: fed/_private/grpc_options.py
-Comment: 
-
 Filename: fed/_private/serialization_utils.py
 Comment: 
 
 Filename: fed/grpc/__init__.py
 Comment: 
 
 Filename: fed/grpc/fed_pb2_grpc_in_protobuf3.py
@@ -63,23 +60,26 @@
 
 Filename: fed/proxy/__init__.py
 Comment: 
 
 Filename: fed/proxy/barriers.py
 Comment: 
 
-Filename: rayfed_nightly-0.1.0b20230715.dev0.dist-info/LICENSE
+Filename: fed/proxy/base_proxy.py
+Comment: 
+
+Filename: rayfed_nightly-0.1.0b20230719.dev0.dist-info/LICENSE
 Comment: 
 
-Filename: rayfed_nightly-0.1.0b20230715.dev0.dist-info/METADATA
+Filename: rayfed_nightly-0.1.0b20230719.dev0.dist-info/METADATA
 Comment: 
 
-Filename: rayfed_nightly-0.1.0b20230715.dev0.dist-info/WHEEL
+Filename: rayfed_nightly-0.1.0b20230719.dev0.dist-info/WHEEL
 Comment: 
 
-Filename: rayfed_nightly-0.1.0b20230715.dev0.dist-info/top_level.txt
+Filename: rayfed_nightly-0.1.0b20230719.dev0.dist-info/top_level.txt
 Comment: 
 
-Filename: rayfed_nightly-0.1.0b20230715.dev0.dist-info/RECORD
+Filename: rayfed_nightly-0.1.0b20230719.dev0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## fed/api.py

```diff
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import functools
 import inspect
 import logging
-from typing import Any, Dict, List, Union
+from typing import Any, Dict, List, Union, Optional
 
 import cloudpickle
 import ray
 
 import fed._private.compatible_utils as compatible_utils
 import fed.config as fed_config
 import fed.utils as fed_utils
@@ -30,35 +30,31 @@
 from fed.proxy.barriers import (
     ping_others,
     recv,
     send,
     start_recv_proxy,
     start_send_proxy,
 )
+from fed.proxy.grpc.grpc_proxy import SendProxy, RecvProxy
+from fed.config import CrossSiloMsgConfig
 from fed.fed_object import FedObject
 from fed.utils import is_ray_object_refs, setup_logger
 
 logger = logging.getLogger(__name__)
 
 
 def init(
     cluster: Dict = None,
     party: str = None,
     tls_config: Dict = None,
     logging_level: str = 'info',
-    cross_silo_grpc_retry_policy: Dict = None,
-    cross_silo_send_max_retries: int = None,
-    cross_silo_serializing_allowed_list: Dict = None,
-    cross_silo_send_resource_label: Dict = None,
-    cross_silo_recv_resource_label: Dict = None,
-    exit_on_failure_cross_silo_sending: bool = False,
-    cross_silo_messages_max_size_in_bytes: int = None,
-    cross_silo_timeout_in_seconds: int = 60,
     enable_waiting_for_other_parties_ready: bool = False,
-    grpc_metadata: Dict = None,
+    send_proxy_cls: SendProxy = None,
+    recv_proxy_cls: RecvProxy = None,
+    global_cross_silo_msg_config: Optional[CrossSiloMsgConfig] = None,
     **kwargs,
 ):
     """
     Initialize a RayFed client.
 
     Args:
         cluster: optional; a dict describes the cluster config. E.g.
@@ -67,37 +63,32 @@
                 {
                     'alice': {
                         # The address for other parties.
                         'address': '127.0.0.1:10001',
                         # (Optional) the listen address, the `address` will be
                         # used if not provided.
                         'listen_addr': '0.0.0.0:10001',
-                        # (Optional) The party specific metadata sent with the grpc request
-                        'grpc_metadata': (('token', 'alice-token'),),
-                        'grpc_options': [
-                            ('grpc.default_authority', 'alice'),
-                            ('grpc.max_send_message_length', 50 * 1024 * 1024)
-                        ]
+                        'cross_silo_msg_config': CrossSiloMsgConfig
                     },
                     'bob': {
                         # The address for other parties.
                         'address': '127.0.0.1:10002',
                         # (Optional) the listen address, the `address` will be
                         # used if not provided.
                         'listen_addr': '0.0.0.0:10002',
-                        # (Optional) The party specific metadata sent with the grpc request
+                        # (Optional) The party specific metadata sent with grpc requests
                         'grpc_metadata': (('token', 'bob-token'),),
                     },
                     'carol': {
                         # The address for other parties.
                         'address': '127.0.0.1:10003',
                         # (Optional) the listen address, the `address` will be
                         # used if not provided.
                         'listen_addr': '0.0.0.0:10003',
-                        # (Optional) The party specific metadata sent with the grpc request
+                        # (Optional) The party specific metadata sent with grpc requests
                         'grpc_metadata': (('token', 'carol-token'),),
                     },
                 }
         party: optional; self party.
         tls_config: optional; a dict describes the tls config. E.g.
             For alice,
 
@@ -112,56 +103,21 @@
 
             .. code:: python
                 {
                     "ca_cert": "root ca cert of other parties.",
                     "cert": "bob's server cert",
                     "key": "bob's server cert key",
                 }
-
         logging_level: optional; the logging level, could be `debug`, `info`,
             `warning`, `error`, `critical`, not case sensititive.
-        cross_silo_grpc_retry_policy: a dict descibes the retry policy for
-            cross silo rpc call. If None, the following default retry policy
-            will be used. More details please refer to
-            `retry-policy <https://github.com/grpc/proposal/blob/master/A6-client-retries.md#retry-policy>`_. # noqa
-
-            .. code:: python
-                {
-                    "maxAttempts": 4,
-                    "initialBackoff": "0.1s",
-                    "maxBackoff": "1s",
-                    "backoffMultiplier": 2,
-                    "retryableStatusCodes": [
-                        "UNAVAILABLE"
-                    ]
-                }
-        cross_silo_send_max_retries: the max retries for sending data cross silo.
-        cross_silo_serializing_allowed_list: The package or class list allowed for
-            serializing(deserializating) cross silos. It's used for avoiding pickle
-            deserializing execution attack when crossing solis.
-        cross_silo_send_resource_label: Customized resource label, the SendProxyActor
-            will be scheduled based on the declared resource label. For example,
-            when setting to `{"my_label": 1}`, then the SendProxyActor will be started
-            only on Nodes with `{"resource": {"my_label": $NUM}}` where $NUM >= 1.
-        cross_silo_recv_resource_label: Customized resource label, the RecverProxyActor
-            will be scheduled based on the declared resource label. For example,
-            when setting to `{"my_label": 1}`, then the RecverProxyActor will be started
-            only on Nodes with `{"resource": {"my_label": $NUM}}` where $NUM >= 1.
-        exit_on_failure_cross_silo_sending: whether exit when failure on
-            cross-silo sending. If True, a SIGTERM will be signaled to self
-            if failed to sending cross-silo data.
-        cross_silo_messages_max_size_in_bytes: The maximum length in bytes of
-            cross-silo messages.
-            If None, the default value of 500 MB is specified.
-        cross_silo_timeout_in_seconds: The timeout in seconds of a cross-silo RPC call.
-            It's 60 by default.
         enable_waiting_for_other_parties_ready: ping other parties until they
             are all ready if True.
-        grpc_metadata: optional; The metadata sent with the grpc request. This won't override
-            basic tcp headers, such as `user-agent`, but aggregate them together.
+        global_cross_silo_msg_config: Global cross-silo message related
+            configs that are applied to all connections. Supported configs
+            can refer to CrossSiloMsgConfig in config.py.
 
     Examples:
         >>> import fed
         >>> import ray
         >>> ray.init(address='local')
         >>> cluster = {
         >>>    'alice': {'address': '127.0.0.1:10001'},
@@ -178,30 +134,29 @@
     fed_utils.validate_cluster_info(cluster)
 
     tls_config = {} if tls_config is None else tls_config
     if tls_config:
         assert (
             'cert' in tls_config and 'key' in tls_config
         ), 'Cert or key are not in tls_config.'
+
+    global_cross_silo_msg_config = \
+        global_cross_silo_msg_config or CrossSiloMsgConfig()
     # A Ray private accessing, should be replaced in public API.
     compatible_utils._init_internal_kv()
 
     cluster_config = {
         constants.KEY_OF_CLUSTER_ADDRESSES: cluster,
         constants.KEY_OF_CURRENT_PARTY_NAME: party,
         constants.KEY_OF_TLS_CONFIG: tls_config,
-        constants.KEY_OF_CROSS_SILO_SERIALIZING_ALLOWED_LIST:
-            cross_silo_serializing_allowed_list,
-        constants.KEY_OF_CROSS_SILO_MESSAGES_MAX_SIZE_IN_BYTES:
-            cross_silo_messages_max_size_in_bytes,
-        constants.KEY_OF_CROSS_SILO_TIMEOUT_IN_SECONDS: cross_silo_timeout_in_seconds,
     }
 
     job_config = {
-        constants.KEY_OF_GRPC_METADATA : grpc_metadata,
+        constants.KEY_OF_CROSS_SILO_MSG_CONFIG:
+            global_cross_silo_msg_config,
     }
     compatible_utils.kv.put(constants.KEY_OF_CLUSTER_CONFIG,
                             cloudpickle.dumps(cluster_config))
     compatible_utils.kv.put(constants.KEY_OF_JOB_CONFIG, cloudpickle.dumps(job_config))
     # Set logger.
     # Note(NKcqx): This should be called after internal_kv has party value, i.e.
     # after `ray.init` and
@@ -211,38 +166,43 @@
         logging_format=constants.RAYFED_LOG_FMT,
         date_format=constants.RAYFED_DATE_FMT,
         party_val=_get_party(),
     )
 
     logger.info(f'Started rayfed with {cluster_config}')
     get_global_context().get_cleanup_manager().start(
-        exit_when_failure_sending=exit_on_failure_cross_silo_sending)
+        exit_when_failure_sending=global_cross_silo_msg_config.exit_on_sending_failure)
 
-    recv_actor_config = fed_config.ProxyActorConfig(
-        resource_label=cross_silo_recv_resource_label)
+    if recv_proxy_cls is None:
+        logger.debug(
+            "Not declaring recver proxy class, using `GrpcRecvProxy` as default.")
+        from fed.proxy.grpc.grpc_proxy import GrpcRecvProxy
+        recv_proxy_cls = GrpcRecvProxy
     # Start recv proxy
     start_recv_proxy(
         cluster=cluster,
         party=party,
         logging_level=logging_level,
         tls_config=tls_config,
-        retry_policy=cross_silo_grpc_retry_policy,
-        actor_config=recv_actor_config
+        proxy_cls=recv_proxy_cls,
+        proxy_config=global_cross_silo_msg_config
     )
 
-    send_actor_config = fed_config.ProxyActorConfig(
-        resource_label=cross_silo_send_resource_label)
+    if send_proxy_cls is None:
+        logger.debug(
+            "Not declaring send proxy class, using `GrpcSendProxy` as default.")
+        from fed.proxy.grpc.grpc_proxy import GrpcSendProxy
+        send_proxy_cls = GrpcSendProxy
     start_send_proxy(
         cluster=cluster,
         party=party,
         logging_level=logging_level,
         tls_config=tls_config,
-        retry_policy=cross_silo_grpc_retry_policy,
-        max_retries=cross_silo_send_max_retries,
-        actor_config=send_actor_config
+        proxy_cls=send_proxy_cls,
+        proxy_config=global_cross_silo_msg_config
     )
 
     if enable_waiting_for_other_parties_ready:
         # TODO(zhouaihui): can be removed after we have a better retry strategy.
         ping_others(cluster=cluster, self_party=party, max_retries=3600)
```

## fed/config.py

```diff
@@ -3,15 +3,18 @@
 """This module should be cached locally due to all configurations
    are mutable.
 """
 
 import fed._private.compatible_utils as compatible_utils
 import fed._private.constants as fed_constants
 import cloudpickle
-from typing import Dict, Optional
+import json
+
+from typing import Dict, List, Optional
+from dataclasses import dataclass
 
 
 class ClusterConfig:
     """A local cache of cluster configuration items."""
     def __init__(self, raw_bytes: bytes) -> None:
         self._data = cloudpickle.loads(raw_bytes)
 
@@ -23,37 +26,27 @@
     def current_party(self):
         return self._data[fed_constants.KEY_OF_CURRENT_PARTY_NAME]
 
     @property
     def tls_config(self):
         return self._data[fed_constants.KEY_OF_TLS_CONFIG]
 
-    @property
-    def serializing_allowed_list(self):
-        return self._data[fed_constants.KEY_OF_CROSS_SILO_SERIALIZING_ALLOWED_LIST]
-
-    @property
-    def cross_silo_timeout(self):
-        return self._data[fed_constants.KEY_OF_CROSS_SILO_TIMEOUT_IN_SECONDS]
-
-    @property
-    def cross_silo_messages_max_size(self):
-        return self._data[fed_constants.KEY_OF_CROSS_SILO_MESSAGES_MAX_SIZE_IN_BYTES]
-
 
 class JobConfig:
     def __init__(self, raw_bytes: bytes) -> None:
         if raw_bytes is None:
             self._data = {}
         else:
             self._data = cloudpickle.loads(raw_bytes)
 
     @property
-    def grpc_metadata(self):
-        return self._data.get(fed_constants.KEY_OF_GRPC_METADATA, {})
+    def cross_silo_msg_config(self):
+        return self._data.get(
+            fed_constants.KEY_OF_CROSS_SILO_MSG_CONFIG,
+            CrossSiloMsgConfig())
 
 
 # A module level cache for the cluster configurations.
 _cluster_config = None
 
 _job_config = None
 
@@ -76,18 +69,98 @@
         compatible_utils._init_internal_kv()
         compatible_utils.kv.initialize()
         raw_dict = compatible_utils.kv.get(fed_constants.KEY_OF_JOB_CONFIG)
         _job_config = JobConfig(raw_dict)
     return _job_config
 
 
-class ProxyActorConfig:
+@dataclass
+class CrossSiloMsgConfig:
     """A class to store parameters used for Proxy Actor
 
     Attributes:
-        resource_label: The customized resources for the actor. This will be
-            filled into the "resource" field of Ray ActorClass.options.
+        proxy_max_restarts: The max restart times for the send proxy.
+        serializing_allowed_list: The package or class list allowed for
+            serializing(deserializating) cross silos. It's used for avoiding pickle
+            deserializing execution attack when crossing solis.
+        send_resource_label: Customized resource label, the SendProxyActor
+            will be scheduled based on the declared resource label. For example,
+            when setting to `{"my_label": 1}`, then the SendProxyActor will be started
+            only on Nodes with `{"resource": {"my_label": $NUM}}` where $NUM >= 1.
+        recv_resource_label: Customized resource label, the RecverProxyActor
+            will be scheduled based on the declared resource label. For example,
+            when setting to `{"my_label": 1}`, then the RecverProxyActor will be started
+            only on Nodes with `{"resource": {"my_label": $NUM}}` where $NUM >= 1.
+        exit_on_sending_failure: whether exit when failure on
+            cross-silo sending. If True, a SIGTERM will be signaled to self
+            if failed to sending cross-silo data.
+        messages_max_size_in_bytes: The maximum length in bytes of
+            cross-silo messages.
+            If None, the default value of 500 MB is specified.
+        timeout_in_ms: The timeout in mili-seconds of a cross-silo RPC call.
+            It's 60000 by default.
+        http_header: The HTTP header, e.g. metadata in grpc, sent with the RPC request.
+            This won't override basic tcp headers, such as `user-agent`, but concat
+            them together.
+    """
+    proxy_max_restarts: int = None
+    timeout_in_ms: int = 60000
+    messages_max_size_in_bytes: int = None
+    exit_on_sending_failure: Optional[bool] = False
+    serializing_allowed_list: Optional[Dict[str, str]] = None
+    send_resource_label: Optional[Dict[str, str]] = None
+    recv_resource_label: Optional[Dict[str, str]] = None
+    http_header: Optional[Dict[str, str]] = None
+
+    def __json__(self):
+        return json.dumps(self.__dict__)
+
+    @classmethod
+    def from_json(cls, json_str):
+        data = json.loads(json_str)
+        return cls(**data)
+
+    @classmethod
+    def from_dict(cls, data: Dict):
+        """Initialize CrossSiloMsgConfig from a dictionary.
+
+        Args:
+            data (Dict): Dictionary with keys as member variable names.
+
+        Returns:
+            CrossSiloMsgConfig: An instance of CrossSiloMsgConfig.
+        """
+        # Get the attributes of the class
+        attrs = {attr for attr, _ in cls.__annotations__.items()}
+        # Filter the dictionary to only include keys that are attributes of the class
+        filtered_data = {key: value for key, value in data.items() if key in attrs}
+        return cls(**filtered_data)
+
+
+@dataclass
+class GrpcCrossSiloMsgConfig(CrossSiloMsgConfig):
+    """A class to store parameters used for GRPC communication
+
+    Attributes:
+        grpc_retry_policy: a dict descibes the retry policy for
+            cross silo rpc call. If None, the following default retry policy
+            will be used. More details please refer to
+            `retry-policy <https://github.com/grpc/proposal/blob/master/A6-client-retries.md#retry-policy>`_. # noqa
+
+            .. code:: python
+                {
+                    "maxAttempts": 4,
+                    "initialBackoff": "0.1s",
+                    "maxBackoff": "1s",
+                    "backoffMultiplier": 2,
+                    "retryableStatusCodes": [
+                        "UNAVAILABLE"
+                    ]
+                }
+        grpc_channel_options: A list of tuples to store GRPC channel options,
+            e.g. [
+                    ('grpc.enable_retries', 1),
+                    ('grpc.max_send_message_length', 50 * 1024 * 1024)
+                ]
     """
-    def __init__(
-            self,
-            resource_label: Optional[Dict[str, str]] = None) -> None:
-        self.resource_label = resource_label
+    grpc_channel_options: List = None
+    grpc_retry_policy: Dict[str, str] = None
```

## fed/_private/constants.py

```diff
@@ -21,18 +21,14 @@
 
 KEY_OF_CLUSTER_ADDRESSES = "CLUSTER_ADDRESSES"
 
 KEY_OF_CURRENT_PARTY_NAME = "CURRENT_PARTY_NAME"
 
 KEY_OF_TLS_CONFIG = "TLS_CONFIG"
 
-KEY_OF_CROSS_SILO_SERIALIZING_ALLOWED_LIST = "CROSS_SILO_SERIALIZING_ALLOWED_LIST" # noqa
-
-KEY_OF_CROSS_SILO_MESSAGES_MAX_SIZE_IN_BYTES = "CROSS_SILO_MESSAGES_MAX_SIZE_IN_BYTES" # noqa
-
-KEY_OF_CROSS_SILO_TIMEOUT_IN_SECONDS = "CROSS_SILO_TIMEOUT_IN_SECONDS"
+KEY_OF_CROSS_SILO_MSG_CONFIG = "CROSS_SILO_MSG_CONFIG"
 
 RAYFED_LOG_FMT = "%(asctime)s %(levelname)s %(filename)s:%(lineno)s [%(party)s] --  %(message)s" # noqa
 
 RAYFED_DATE_FMT = "%Y-%m-%d %H:%M:%S"
 
 RAY_VERSION_2_0_0_STR = "2.0.0"
```

## fed/_private/serialization_utils.py

```diff
@@ -59,15 +59,16 @@
         file, fix_imports=fix_imports, buffers=buffers, encoding=encoding, errors=errors
     ).load()
 
 
 def _apply_loads_function_with_whitelist():
     global _pickle_whitelist
 
-    _pickle_whitelist = fed_config.get_cluster_config().serializing_allowed_list
+    _pickle_whitelist = fed_config.get_job_config() \
+        .cross_silo_msg_config.serializing_allowed_list
     if _pickle_whitelist is None:
         return
 
     if "*" in _pickle_whitelist:
         _pickle_whitelist = None
         return
```

## fed/proxy/barriers.py

```diff
@@ -8,39 +8,26 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import asyncio
 import logging
-import threading
 import time
 import copy
 from typing import Dict, Optional
 
-import cloudpickle
-import grpc
 import ray
 
 import fed.config as fed_config
-import fed.utils as fed_utils
-from fed._private import constants
-from fed._private.grpc_options import get_grpc_options, set_max_message_length
-import fed._private.compatible_utils as compatible_utils
-from fed.config import get_cluster_config
-if compatible_utils._compare_version_strings(
-        fed_utils.get_package_version('protobuf'), '4.0.0'):
-    from fed.grpc import fed_pb2_in_protobuf4 as fed_pb2
-    from fed.grpc import fed_pb2_grpc_in_protobuf4 as fed_pb2_grpc
-else:
-    from fed.grpc import fed_pb2_in_protobuf3 as fed_pb2
-    from fed.grpc import fed_pb2_grpc_in_protobuf3 as fed_pb2_grpc
+from fed.config import get_job_config
+from fed.proxy.base_proxy import SendProxy, RecvProxy
 from fed.utils import setup_logger
+from fed._private import constants
 from fed._private.global_context import get_global_context
 
 logger = logging.getLogger(__name__)
 
 
 def key_exists_in_two_dim_dict(the_dict, key_a, key_b) -> bool:
     key_a, key_b = str(key_a), str(key_b)
@@ -63,133 +50,42 @@
 
 
 def pop_from_two_dim_dict(the_dict, key_a, key_b):
     key_a, key_b = str(key_a), str(key_b)
     return the_dict[key_a].pop(key_b)
 
 
-class SendDataService(fed_pb2_grpc.GrpcServiceServicer):
-    def __init__(self, all_events, all_data, party, lock):
-        self._events = all_events
-        self._all_data = all_data
-        self._party = party
-        self._lock = lock
-
-    async def SendData(self, request, context):
-        upstream_seq_id = request.upstream_seq_id
-        downstream_seq_id = request.downstream_seq_id
-        logger.debug(
-            f'Received a grpc data request from {upstream_seq_id} to '
-            f'{downstream_seq_id}.'
-        )
-
-        with self._lock:
-            add_two_dim_dict(
-                self._all_data, upstream_seq_id, downstream_seq_id, request.data
-            )
-            if not key_exists_in_two_dim_dict(
-                self._events, upstream_seq_id, downstream_seq_id
-            ):
-                event = asyncio.Event()
-                add_two_dim_dict(
-                    self._events, upstream_seq_id, downstream_seq_id, event
-                )
-        event = get_from_two_dim_dict(self._events, upstream_seq_id, downstream_seq_id)
-        event.set()
-        logger.debug(f"Event set for {upstream_seq_id}")
-        return fed_pb2.SendDataResponse(result="OK")
-
-
-async def _run_grpc_server(
-    port, event, all_data, party, lock,
-    server_ready_future, tls_config=None, grpc_options=None
-):
-    server = grpc.aio.server(options=grpc_options)
-    fed_pb2_grpc.add_GrpcServiceServicer_to_server(
-        SendDataService(event, all_data, party, lock), server
-    )
-
-    tls_enabled = fed_utils.tls_enabled(tls_config)
-    if tls_enabled:
-        ca_cert, private_key, cert_chain = fed_utils.load_cert_config(tls_config)
-        server_credentials = grpc.ssl_server_credentials(
-            [(private_key, cert_chain)],
-            root_certificates=ca_cert,
-            require_client_auth=ca_cert is not None,
-        )
-        server.add_secure_port(f'[::]:{port}', server_credentials)
-    else:
-        server.add_insecure_port(f'[::]:{port}')
-
-    msg = f"Succeeded to add port {port}."
-    await server.start()
-    logger.info(
-        f'Successfully start Grpc service with{"out" if not tls_enabled else ""} '
-        'credentials.'
-    )
-    server_ready_future.set_result((True, msg))
-    await server.wait_for_termination()
-
-
-async def send_data_grpc(
-    data,
-    stub,
-    upstream_seq_id,
-    downstream_seq_id,
-    metadata=None,
-):
-    cluster_config = fed_config.get_cluster_config()
-    data = cloudpickle.dumps(data)
-    request = fed_pb2.SendDataRequest(
-        data=data,
-        upstream_seq_id=str(upstream_seq_id),
-        downstream_seq_id=str(downstream_seq_id),
-    )
-    # Waiting for the reply from downstream.
-    response = await stub.SendData(
-        request,
-        metadata=fed_utils.dict2tuple(metadata),
-        timeout=cluster_config.cross_silo_timeout,
-    )
-    logger.debug(
-        f'Received data response from seq_id {downstream_seq_id}, '
-        f'result: {response.result}.'
-    )
-    return response.result
-
-
 @ray.remote
 class SendProxyActor:
     def __init__(
         self,
         cluster: Dict,
         party: str,
         tls_config: Dict = None,
         logging_level: str = None,
-        retry_policy: Dict = None,
+        proxy_cls=None
     ):
         setup_logger(
             logging_level=logging_level,
             logging_format=constants.RAYFED_LOG_FMT,
             date_format=constants.RAYFED_DATE_FMT,
             party_val=party,
         )
+
         self._stats = {"send_op_count": 0}
         self._cluster = cluster
         self._party = party
         self._tls_config = tls_config
-        self.retry_policy = retry_policy
-        self._grpc_metadata = fed_config.get_job_config().grpc_metadata
-        # Mapping the destination party name to the reused client stub.
-        self._stubs = {}
-        cluster_config = fed_config.get_cluster_config()
-        set_max_message_length(cluster_config.cross_silo_messages_max_size)
+        cross_silo_msg_config = fed_config.get_job_config().cross_silo_msg_config
+        self._proxy_instance: SendProxy = proxy_cls(
+            cluster, party, tls_config, cross_silo_msg_config)
 
     async def is_ready(self):
-        return True
+        res = await self._proxy_instance.is_ready()
+        return res
 
     async def send(
         self,
         dest_party,
         data,
         upstream_seq_id,
         downstream_seq_id,
@@ -202,206 +98,116 @@
             f'send data to seq_id {downstream_seq_id} of {dest_party} '
             f'from {upstream_seq_id}'
         )
         logger.debug(
             f'Sending {send_log_msg} with{"out" if not self._tls_config else ""}'
             ' credentials.'
         )
-        dest_addr = self._cluster[dest_party]['address']
-        dest_party_grpc_config = self.setup_grpc_config(dest_party)
         try:
-            tls_enabled = fed_utils.tls_enabled(self._tls_config)
-            grpc_options = dest_party_grpc_config['grpc_options']
-            grpc_options = get_grpc_options(retry_policy=self.retry_policy) if \
-                grpc_options is None else fed_utils.dict2tuple(grpc_options)
-
-            if dest_party not in self._stubs:
-                if tls_enabled:
-                    ca_cert, private_key, cert_chain = fed_utils.load_cert_config(
-                        self._tls_config)
-                    credentials = grpc.ssl_channel_credentials(
-                        certificate_chain=cert_chain,
-                        private_key=private_key,
-                        root_certificates=ca_cert,
-                    )
-                    channel = grpc.aio.secure_channel(
-                        dest_addr, credentials, options=grpc_options)
-                else:
-                    channel = grpc.aio.insecure_channel(dest_addr, options=grpc_options)
-                stub = fed_pb2_grpc.GrpcServiceStub(channel)
-                self._stubs[dest_party] = stub
-
-            response = await send_data_grpc(
-                data=data,
-                stub=self._stubs[dest_party],
-                upstream_seq_id=upstream_seq_id,
-                downstream_seq_id=downstream_seq_id,
-                metadata=dest_party_grpc_config['grpc_metadata'],
-            )
+            response = await self._proxy_instance.send(
+                dest_party, data, upstream_seq_id, downstream_seq_id)
         except Exception as e:
             logger.error(f'Failed to {send_log_msg}, error: {e}')
             return False
         logger.debug(f"Succeeded to send {send_log_msg}. Response is {response}")
         return True  # True indicates it's sent successfully.
 
-    def setup_grpc_config(self, dest_party):
-        dest_party_grpc_config = {}
-        global_grpc_metadata = (
-            dict(self._grpc_metadata) if self._grpc_metadata is not None else {}
-        )
-        dest_party_grpc_metadata = dict(
-            self._cluster[dest_party].get('grpc_metadata', {})
-        )
-        # merge grpc metadata
-        dest_party_grpc_config['grpc_metadata'] = {
-            **global_grpc_metadata, **dest_party_grpc_metadata}
-
-        global_grpc_options = dict(get_grpc_options(self.retry_policy))
-        dest_party_grpc_options = dict(
-            self._cluster[dest_party].get('grpc_options', {})
-        )
-        dest_party_grpc_config['grpc_options'] = {
-            **global_grpc_options, **dest_party_grpc_options}
-        return dest_party_grpc_config
-
     async def _get_stats(self):
         return self._stats
 
-    async def _get_grpc_options(self):
-        return get_grpc_options()
-
     async def _get_cluster_info(self):
         return self._cluster
 
+    async def _get_proxy_config(self, dest_party=None):
+        return await self._proxy_instance.get_proxy_config(dest_party)
+
 
 @ray.remote
 class RecverProxyActor:
     def __init__(
         self,
         listen_addr: str,
         party: str,
         logging_level: str,
         tls_config=None,
-        retry_policy: Dict = None,
+        proxy_cls=None,
     ):
         setup_logger(
             logging_level=logging_level,
             logging_format=constants.RAYFED_LOG_FMT,
             date_format=constants.RAYFED_DATE_FMT,
             party_val=party,
         )
         self._stats = {"receive_op_count": 0}
         self._listen_addr = listen_addr
         self._party = party
         self._tls_config = tls_config
-        self.retry_policy = retry_policy
-        config = fed_config.get_cluster_config()
-        set_max_message_length(config.cross_silo_messages_max_size)
-        # Workaround the threading coordinations
-
-        # Flag to see whether grpc server starts
-        self._server_ready_future = asyncio.Future()
-
-        # All events for grpc waitting usage.
-        self._events = {}  # map from (upstream_seq_id, downstream_seq_id) to event
-        self._all_data = {}  # map from (upstream_seq_id, downstream_seq_id) to data
-        self._lock = threading.Lock()
+        cross_silo_msg_config = fed_config.get_job_config().cross_silo_msg_config
+        self._proxy_instance: RecvProxy = proxy_cls(
+            listen_addr, party, tls_config, cross_silo_msg_config)
 
-    async def run_grpc_server(self):
-        try:
-            port = self._listen_addr[self._listen_addr.index(':') + 1 :]
-            await _run_grpc_server(
-                port,
-                self._events,
-                self._all_data,
-                self._party,
-                self._lock,
-                self._server_ready_future,
-                self._tls_config,
-                get_grpc_options(self.retry_policy),
-            )
-        except RuntimeError as err:
-            msg = f'Grpc server failed to listen to port: {port}' \
-                  f' Try another port by setting `listen_addr` into `cluster` config' \
-                  f' when calling `fed.init`. Grpc error msg: {err}'
-            self._server_ready_future.set_result((False, msg))
+    async def start(self):
+        await self._proxy_instance.start()
 
     async def is_ready(self):
-        await self._server_ready_future
-        return self._server_ready_future.result()
+        res = await self._proxy_instance.is_ready()
+        return res
 
-    async def get_data(self, src_aprty, upstream_seq_id, curr_seq_id):
+    async def get_data(self, src_party, upstream_seq_id, curr_seq_id):
         self._stats["receive_op_count"] += 1
-        data_log_msg = f"data for {curr_seq_id} from {upstream_seq_id} of {src_aprty}"
-        logger.debug(f"Getting {data_log_msg}")
-        with self._lock:
-            if not key_exists_in_two_dim_dict(
-                self._events, upstream_seq_id, curr_seq_id
-            ):
-                add_two_dim_dict(
-                    self._events, upstream_seq_id, curr_seq_id, asyncio.Event()
-                )
-        curr_event = get_from_two_dim_dict(self._events, upstream_seq_id, curr_seq_id)
-        await curr_event.wait()
-        logging.debug(f"Waited {data_log_msg}.")
-        with self._lock:
-            data = pop_from_two_dim_dict(self._all_data, upstream_seq_id, curr_seq_id)
-            pop_from_two_dim_dict(self._events, upstream_seq_id, curr_seq_id)
-
-        # NOTE(qwang): This is used to avoid the conflict with pickle5 in Ray.
-        import fed._private.serialization_utils as fed_ser_utils
-        fed_ser_utils._apply_loads_function_with_whitelist()
-        return cloudpickle.loads(data)
+        data = await self._proxy_instance.get_data(
+            src_party, upstream_seq_id, curr_seq_id)
+        return data
 
     async def _get_stats(self):
         return self._stats
 
-    async def _get_grpc_options(self):
-        return get_grpc_options()
+    async def _get_proxy_config(self):
+        return await self._proxy_instance.get_proxy_config()
 
 
 _DEFAULT_RECV_PROXY_OPTIONS = {
     "max_concurrency": 1000,
 }
 
 
 def start_recv_proxy(
     cluster: str,
     party: str,
     logging_level: str,
     tls_config=None,
-    retry_policy=None,
-    actor_config: Optional[fed_config.ProxyActorConfig] = None
+    proxy_cls=None,
+    proxy_config: Optional[fed_config.CrossSiloMsgConfig] = None
 ):
 
     # Create RecevrProxyActor
     # Not that this is now a threaded actor.
     # NOTE(NKcqx): This is not just addr, but a party dict containing 'address'
     party_addr = cluster[party]
     listen_addr = party_addr.get('listen_addr', None)
     if not listen_addr:
         listen_addr = party_addr['address']
 
     actor_options = copy.deepcopy(_DEFAULT_RECV_PROXY_OPTIONS)
-    if actor_config is not None and actor_config.resource_label is not None:
-        actor_options.update({"resources": actor_config.resource_label})
+    if proxy_config is not None and proxy_config.recv_resource_label is not None:
+        actor_options.update({"resources": proxy_config.recv_resource_label})
 
     logger.debug(f"Starting RecvProxyActor with options: {actor_options}")
 
     recver_proxy_actor = RecverProxyActor.options(
         name=f"RecverProxyActor-{party}", **actor_options
     ).remote(
         listen_addr=listen_addr,
         party=party,
         tls_config=tls_config,
         logging_level=logging_level,
-        retry_policy=retry_policy,
+        proxy_cls=proxy_cls
     )
-    recver_proxy_actor.run_grpc_server.remote()
-    timeout = get_cluster_config().cross_silo_timeout
+    recver_proxy_actor.start.remote()
+    timeout = proxy_config.timeout_in_ms / 1000 if proxy_config is not None else 60
     server_state = ray.get(recver_proxy_actor.is_ready.remote(), timeout=timeout)
     assert server_state[0], server_state[1]
     logger.info("RecverProxy has successfully created.")
 
 
 _SEND_PROXY_ACTOR = None
 _DEFAULT_SEND_PROXY_OPTIONS = {
@@ -410,42 +216,41 @@
 
 
 def start_send_proxy(
     cluster: Dict,
     party: str,
     logging_level: str,
     tls_config: Dict = None,
-    retry_policy=None,
-    max_retries=None,
-    actor_config: Optional[fed_config.ProxyActorConfig] = None
+    proxy_cls=None,
+    proxy_config: Optional[fed_config.CrossSiloMsgConfig] = None
 ):
     # Create SendProxyActor
     global _SEND_PROXY_ACTOR
 
     actor_options = copy.deepcopy(_DEFAULT_SEND_PROXY_OPTIONS)
-    if max_retries is not None:
+    if proxy_config and proxy_config.proxy_max_restarts:
         actor_options.update({
-            "max_task_retries": max_retries,
+            "max_task_retries": proxy_config.proxy_max_restarts,
             "max_restarts": 1,
             })
-    if actor_config is not None and actor_config.resource_label is not None:
-        actor_options.update({"resources": actor_config.resource_label})
+    if proxy_config and proxy_config.send_resource_label:
+        actor_options.update({"resources": proxy_config.send_resource_label})
 
     logger.debug(f"Starting SendProxyActor with options: {actor_options}")
     _SEND_PROXY_ACTOR = SendProxyActor.options(
         name="SendProxyActor", **actor_options)
 
     _SEND_PROXY_ACTOR = _SEND_PROXY_ACTOR.remote(
         cluster=cluster,
         party=party,
         tls_config=tls_config,
         logging_level=logging_level,
-        retry_policy=retry_policy,
+        proxy_cls=proxy_cls
     )
-    timeout = get_cluster_config().cross_silo_timeout
+    timeout = get_job_config().cross_silo_msg_config.timeout_in_ms / 1000
     assert ray.get(_SEND_PROXY_ACTOR.is_ready.remote(), timeout=timeout)
     logger.info("SendProxyActor has successfully created.")
 
 
 def send(
     dest_party,
     data,
```

## Comparing `rayfed_nightly-0.1.0b20230715.dev0.dist-info/LICENSE` & `rayfed_nightly-0.1.0b20230719.dev0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `rayfed_nightly-0.1.0b20230715.dev0.dist-info/METADATA` & `rayfed_nightly-0.1.0b20230719.dev0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: rayfed-nightly
-Version: 0.1.0b20230715.dev0
+Version: 0.1.0b20230719.dev0
 Summary: A multiple parties joint, distributed execution engine based on Ray,to help build your own federated learning frameworks in minutes.
 Home-page: https://github.com/ray-project/rayfed
 Author: RayFed Team
 Author-email: rayfed-dev@googlegroups.com
 License: Apache 2.0
 Platform: UNKNOWN
 Description-Content-Type: text/markdown
```

## Comparing `rayfed_nightly-0.1.0b20230715.dev0.dist-info/RECORD` & `rayfed_nightly-0.1.0b20230719.dev0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 fed/__init__.py,sha256=WN5lu4fAPUVxzlL4T6Z_ygmP3d9-DAVLWFRkd92SVmc,859
-fed/api.py,sha256=uPUkIqjHmdvJ7g7SZ4CDCBTM0oTFXh3tXaIdgrywQs8,16807
+fed/api.py,sha256=Z_Wp1xHe8SwpRTj8v0Tix0mXH-LQuCrUM624sTns1SY,14232
 fed/cleanup.py,sha256=LeADQUgJ8n94PJdBqkbM9LbMnA-aZfMPe7bk0MMWZIU,3676
-fed/config.py,sha256=K3pYf4B9tO5FXThxMCkY2l6oeZuBOwOYIn3rX5ATO1c,2721
+fed/config.py,sha256=tsXOrCDqQJkaYqjJyUbmPOzHo3J0vwMBrarM1wAY_I4,6043
 fed/fed_object.py,sha256=l2BRa9WZ3jqXSDjwFPURcAIK8XkH8A5UYA_OcY4TOD0,2877
 fed/tree_util.py,sha256=25LiGASBcreE34OsGsoeRWH4t6BuBk3QVcKjCe38jTI,7908
 fed/utils.py,sha256=mT0yG7aeAEPCTe_ZuGyabIV_tz9-nrjX-d3VDuKlJNQ,7519
 fed/_private/__init__.py,sha256=MDXwlZ-y7_o-tfqh8DVkjlO-6MlWqwLdbSIZUJfXtF0,581
 fed/_private/api.py,sha256=MDXwlZ-y7_o-tfqh8DVkjlO-6MlWqwLdbSIZUJfXtF0,581
 fed/_private/compatible_utils.py,sha256=4JdcL1qGlLwQx6DMBAs5lphPxOIJyz1YqYbS1Hq8Ruk,5269
-fed/_private/constants.py,sha256=r0vt4ueAsB3cyNVOQ8lJZgCCDosYHgNYZblaUfapk1o,1268
+fed/_private/constants.py,sha256=skHnOBeSkbZG7Ch0vTDW5tz9cPehKsx0StFVLFNCpkE,1066
 fed/_private/fed_actor.py,sha256=8nqXO_l9yOno5duMiEhWagp9q9-w696erKos-RgcnoU,3837
 fed/_private/fed_call_holder.py,sha256=RDD3fet8CD2clUNfSX6ByXViaYlkcLQNDxaAADU-Ld4,3947
 fed/_private/global_context.py,sha256=JtRCuBHju_8OcIbtfNvhzPR9bDxeD_X8bRe-8SogNtY,1262
-fed/_private/grpc_options.py,sha256=x9kEjqnOw0uGmixjfc3dsV0qxUUsF1ugK0q0pXHH4ek,2893
-fed/_private/serialization_utils.py,sha256=l63nacVabcyKpys9tVT2zUMmKecimeVflsJ6v45AYvc,2386
+fed/_private/serialization_utils.py,sha256=GjKrmKFvmkaKoAaZo5ikdi5gOOru_b9nywtoTTnMk2U,2415
 fed/grpc/__init__.py,sha256=MDXwlZ-y7_o-tfqh8DVkjlO-6MlWqwLdbSIZUJfXtF0,581
 fed/grpc/fed_pb2_grpc_in_protobuf3.py,sha256=Do9HCVH4CdclNRsX8LASBCrDUtcji8QP8voHl485Qw8,2968
 fed/grpc/fed_pb2_grpc_in_protobuf4.py,sha256=MyuFC-u-QMNNAyHsXRc3TvEq9U4DQ9EjBIGdcPzSQvk,2989
 fed/grpc/fed_pb2_in_protobuf3.py,sha256=wJRyg1d7dK6SHfw7lzQPlEHWkINq8JqiK0qbqXWhRro,2095
 fed/grpc/fed_pb2_in_protobuf4.py,sha256=0JbbKEqCKx31MiIMVU3UOJ93ZgTbAr6g51z1EgIRNG8,2113
 fed/proxy/__init__.py,sha256=zjmMrqPxcVeXa7sMvRccSdnmV8_A73tETlvUJtAd0lA,613
-fed/proxy/barriers.py,sha256=Lzsgt7gtjFrAYWMFrfe9F5tLpXlysZq1EQlMTZDM80w,17215
-rayfed_nightly-0.1.0b20230715.dev0.dist-info/LICENSE,sha256=QwcOLU5TJoTeUhuIXzhdCEEDDvorGiC6-3YTOl4TecE,11356
-rayfed_nightly-0.1.0b20230715.dev0.dist-info/METADATA,sha256=RjjpaLEODHWu4kheiEJ042CJccp-McFlfHnYEpv-6tU,7367
-rayfed_nightly-0.1.0b20230715.dev0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-rayfed_nightly-0.1.0b20230715.dev0.dist-info/top_level.txt,sha256=5gd1qhbpzLAi36ONV8p_s65_-iAiOSwFljYh-ONEwts,4
-rayfed_nightly-0.1.0b20230715.dev0.dist-info/RECORD,,
+fed/proxy/barriers.py,sha256=prUjzzcWLiAzVt2W8IvqRpp9UEzQzmeGPrnyRr1gbBg,9542
+fed/proxy/base_proxy.py,sha256=mGrqjDIIC1D5I0lImX_g9ju-Fq4Q7drgGWk2w9lLgBQ,2001
+rayfed_nightly-0.1.0b20230719.dev0.dist-info/LICENSE,sha256=QwcOLU5TJoTeUhuIXzhdCEEDDvorGiC6-3YTOl4TecE,11356
+rayfed_nightly-0.1.0b20230719.dev0.dist-info/METADATA,sha256=-SOziezex8H506QeMOwpG2X_CBDjTRrIiiQJowcRAUM,7367
+rayfed_nightly-0.1.0b20230719.dev0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+rayfed_nightly-0.1.0b20230719.dev0.dist-info/top_level.txt,sha256=5gd1qhbpzLAi36ONV8p_s65_-iAiOSwFljYh-ONEwts,4
+rayfed_nightly-0.1.0b20230719.dev0.dist-info/RECORD,,
```

